{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IWAE_table2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNl1adNZvk5RXgguFMaBR7q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angzhifan/Importance-Weighted-Autoencoders/blob/main/IWAE_table2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kilr3JzOO7x",
        "outputId": "46f77c3b-f4c8-43b5-fdfb-7d0565969f64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#IWAE experiment 2\n",
        "#Author: Angzhi Fan\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# VAE or IWAE with one layer\n",
        "class VAE_1(nn.Module):\n",
        "    \n",
        "    def __init__(self, t):\n",
        "        super(VAE_1, self).__init__()\n",
        "        self.k = t\n",
        "        self.fc1 = nn.Linear(28*28, 200)\n",
        "        self.fc2 = nn.Linear(200, 200)\n",
        "        self.fc3_mu = nn.Linear(200, 50)\n",
        "        self.fc3_sigma = nn.Linear(200, 50)\n",
        "        self.fc4 = nn.Linear(50, 200)\n",
        "        self.fc5 = nn.Linear(200, 200)\n",
        "        self.fc6 = nn.Linear(200,28*28)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1,1,28*28)\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = torch.tanh(self.fc2(x))\n",
        "        mu = self.fc3_mu(x).view(-1,1,50)\n",
        "        log_sigma = self.fc3_sigma(x).view(-1,1,50)\n",
        "        eps = torch.randn_like(mu.repeat(1,self.k,1))\n",
        "        x = mu.repeat(1,self.k,1) + torch.exp(log_sigma.repeat(1,self.k,1))*eps\n",
        "        x = torch.tanh(self.fc4(x))\n",
        "        x = torch.tanh(self.fc5(x))\n",
        "        x = self.fc6(x)\n",
        "        return x, mu, log_sigma, eps\n",
        "    "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzPMjQRyO17S",
        "outputId": "ff386c44-4b36-4d43-dc00-5a32c993796a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD2GTyYmO5hP",
        "outputId": "d87c3092-0adc-4d89-891f-c5cb0c845d82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def load_data():\n",
        "    train_file = '/content/drive/My Drive/dataset/BinaryMNIST/binarized_mnist_train.amat'\n",
        "    valid_file = '/content/drive/My Drive/dataset/BinaryMNIST/binarized_mnist_valid.amat'\n",
        "    test_file = '/content/drive/My Drive/dataset/BinaryMNIST/binarized_mnist_test.amat'\n",
        "    mnist_train = np.concatenate([np.loadtxt(train_file),np.loadtxt(valid_file)])\n",
        "    mnist_test = np.loadtxt(test_file)\n",
        "    return mnist_train, mnist_test\n",
        "\n",
        "mnist_train, mnist_test = load_data()\n",
        "print(mnist_train.shape)\n",
        "print(mnist_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94GUYXPTO8Cp",
        "outputId": "9a374376-6241-451c-efed-139f13b77311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def test_function_1(net):\n",
        "    testloader = torch.utils.data.DataLoader(mnist_test, batch_size=20,shuffle=False)\n",
        "    nll = 0.0\n",
        "    A_u = torch.zeros(50)\n",
        "    for i,data in enumerate(testloader, 0):\n",
        "      with torch.no_grad():\n",
        "        test = data.view(-1,1,28*28).to(device)\n",
        "        output = net(test.float())\n",
        "        \n",
        "        # stochastic layer\n",
        "        eps = torch.randn_like(output[2].repeat(1,5000,1))\n",
        "        h = output[1].repeat(1,5000,1) + torch.exp(output[2].repeat(1,5000,1))*eps\n",
        "\n",
        "        # output of x using the new epsilon\n",
        "        output_x = torch.tanh(net.fc4(h))\n",
        "        output_x = torch.tanh(net.fc5(output_x))\n",
        "        output_x = net.fc6(output_x)\n",
        "        log_prob_condi = torch.sum(output_x*test.repeat(1,5000,1)-torch.log(1+torch.exp(output_x)), 2)\n",
        "\n",
        "        # log weights, unnormalized\n",
        "        log_weights = log_prob_condi-(h*h).sum(2)/2+(eps*eps).sum(2)/2+output[2].repeat(1,5000,1).sum(2)\n",
        "\n",
        "        # estimate log likelihood using L_5000\n",
        "        L_5000 = log_weights.max(1)[0].mean()+torch.log(torch.exp(log_weights\n",
        "                        -log_weights.max(1)[0].view(-1,1)).mean(1)).mean()\n",
        "        nll -= L_5000.item()\n",
        "        A_u += output[1].view(-1,50).var(0).cpu()\n",
        "    return nll/500, sum(A_u.detach().numpy()/500>0.01)\n",
        "\n",
        "print(\"Finished loading test function 1\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished loading test function 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw_KL46ePBKz"
      },
      "source": [
        "#Initialize it by a stage1_mod and train it using stage2_mod objective function\n",
        "stage2_mod = 'iwae'\n",
        "layer = 1\n",
        "batch_size = 20\n",
        "k = 1\n",
        "continued = 121\n",
        "\n",
        "if stage2_mod == 'iwae':\n",
        "    #this index_vec will be used in the training of iwae\n",
        "    index_vec = torch.tensor([i*k for i in range(batch_size)]).to(device)\n",
        "    stage1_mod = 'vae'\n",
        "elif stage2_mod == 'vae':\n",
        "    stage1_mod = 'iwae'\n",
        "else:\n",
        "    raise Exception(\"Invalid Mode\")\n",
        "\n",
        "net = VAE_1(k)\n",
        "#net.load_state_dict(torch.load('/content/drive/My Drive/IWAE_VAE/model/'+stage1_mod+'_net'+'_layer'+str(layer)+'_k'+str(k)+'_'+'.pth',map_location=torch.device('cpu')))\n",
        "net.load_state_dict(torch.load('/content/drive/My Drive/IWAE_VAE/model/stage1_modvaestage2_modiwae_net_layer1_k1_162.pth',map_location=torch.device('cpu')))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with open('/content/drive/My Drive/IWAE_VAE/outfile_stage1_mod'+stage1_mod+'stage2_mod'+stage2_mod+'_layer'+str(layer)+'_k'+str(k)+'_'+'.txt', 'w') as outfile:\n",
        "    outfile.write('output of the code '+'\\n'+'author:Angzhi Fan fana@uchicago.edu'+'\\n')\n",
        "    \n",
        "start = time.time()\n",
        "trainloader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, \n",
        "                                         shuffle=True, num_workers=2)\n",
        "decay_num = sum(np.array([1, 4, 13, 40, 121, 364, 1093, 3280])<=continued)\n",
        "learning_rate = 0.001/10**(decay_num/7)\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate\n",
        "                             , betas=(0.9, 0.999), eps=1e-04)\n",
        "for epoch in range(continued, continued+81):\n",
        "    if epoch in [continued+80, continued+240]:\n",
        "        PATH = '/content/drive/My Drive/IWAE_VAE/model/stage1_mod'+stage1_mod+'stage2_mod'+stage2_mod+'_net'+'_layer'+str(layer)+'_k'+str(k)+'_'+str(epoch)+'.pth'\n",
        "        torch.save(net.state_dict(), PATH)\n",
        "        with open('/content/drive/My Drive/IWAE_VAE/outfile_stage1_mod'+stage1_mod+'stage2_mod'+stage2_mod+'_layer'+str(layer)+'_k'+str(k)+'_'+'.txt', 'a') as outfile:\n",
        "            if layer == 1:\n",
        "                nll, A_u = test_function_1(net)\n",
        "            else:\n",
        "                nll, A_u = test_function_2(net)\n",
        "            print('NLL:', nll, 'active units:', A_u)\n",
        "            outfile.write('test average (NLL):'+str(nll)+'\\n')\n",
        "            outfile.write('test average (active units):'+str(A_u)+'\\n')\n",
        "            outfile.write('learning rate decay'+'\\n')\n",
        "        print(\"learning rate=\", learning_rate)\n",
        "    if epoch in [1, 4, 13, 40, 121, 364, 1093, 3280]:\n",
        "        PATH = '/content/drive/My Drive/IWAE_VAE/model/stage1_mod'+stage1_mod+'stage2_mod'+stage2_mod+'_net'+'_layer'+str(layer)+'_k'+str(k)+'_'+str(epoch)+'.pth'\n",
        "        torch.save(net.state_dict(), PATH)\n",
        "        learning_rate /= 10**(1/7)\n",
        "        optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate, \n",
        "                                     betas=(0.9, 0.999), eps=1e-04)\n",
        "        with open('/content/drive/My Drive/IWAE_VAE/outfile_stage1_mod'+stage1_mod+'stage2_mod'+stage2_mod+'_layer'+str(layer)+'_k'+str(k)+'_'+'.txt', 'a') as outfile:\n",
        "            if layer == 1:\n",
        "                nll, A_u = test_function_1(net)\n",
        "            else:\n",
        "                nll, A_u = test_function_2(net)\n",
        "            print('NLL:', nll, 'active units:', A_u)\n",
        "            outfile.write('test average (NLL):'+str(nll)+'\\n')\n",
        "            outfile.write('test average (active units):'+str(A_u)+'\\n')\n",
        "            outfile.write('learning rate decay'+'\\n')\n",
        "        print(\"learning rate=\", learning_rate)\n",
        "    running_loss = 0.0\n",
        "    for i,data in enumerate(trainloader, 0):\n",
        "        train = data.view(-1,1,28*28).to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = net(train.float())\n",
        "        log_prob_condi = torch.sum(output[0]*train.repeat(1,k,1)-torch.log(1+torch.exp(output[0])), 2)\n",
        "\n",
        "        if layer == 1:\n",
        "            # stochastic layer\n",
        "            h = (output[1].repeat(1,k,1) + torch.exp(output[2].repeat(1,k,1))*output[3])\n",
        "            # log weights, unnormalized\n",
        "            log_weights = log_prob_condi-(h*h).sum(2)/2+(output[3]*output[3]).sum(2)/2+output[2].repeat(1,k,1).sum(2)\n",
        "        else:\n",
        "            # stochastic layer h1 minus mu3\n",
        "            h1 = output[1].repeat(1,k,1) + torch.exp(output[4].repeat(1,k,1))*output[7]-output[3]\n",
        "            # stochastic layer h2\n",
        "            h2 = (output[2]+torch.exp(output[5])*output[8])\n",
        "            # log weights, unnormalized\n",
        "            log_p_h1_h2 = -(h1*h1/torch.exp(2*output[6])).sum(2)/2-output[6].sum(2)\n",
        "            log_q_h1_x = -(output[7]*output[7]).sum(2)/2-output[4].repeat(1,k,1).sum(2)\n",
        "            log_q_h2_h1 = -(output[8]*output[8]).sum(2)/2-output[5].sum(2)\n",
        "            log_weights = log_prob_condi+log_p_h1_h2-(h2*h2).sum(2)/2-log_q_h1_x-log_q_h2_h1\n",
        "        \n",
        "        log_weights.to(device)\n",
        "        if stage2_mod == 'vae':\n",
        "            loss = -log_weights.mean().to(device)\n",
        "        else:\n",
        "            # sample one index from k sets of hidden values\n",
        "            temp = torch.exp(F.log_softmax(log_weights-log_weights.min(1)[0].view(-1,1),1)).to(device)\n",
        "            temp1 = torch.multinomial(temp,1).flatten().to(device)+index_vec\n",
        "            # estimate loss\n",
        "            loss = -torch.take(log_weights, temp1).mean().to(device)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i%500 == 499:\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                 (epoch+1, i + 1, running_loss/500))\n",
        "            with open('/content/drive/My Drive/IWAE_VAE/outfile_stage1_mod'+stage1_mod+'stage2_mod'+stage2_mod+'_layer'+str(layer)+'_k'+str(k)+'_'+'.txt', 'a') as outfile:\n",
        "                outfile.write('[%d, %5d] loss: %.3f' %\n",
        "                 (epoch+1, i + 1, running_loss/500)+'\\n')\n",
        "            running_loss = 0.0\n",
        "        \n",
        "PATH = '/content/drive/My Drive/IWAE_VAE/model/stage1_mod'+stage1_mod+'stage2_mod'+stage2_mod+'_net'+'_layer'+str(layer)+'_k'+str(k)+'_'+'.pth'\n",
        "torch.save(net.state_dict(), PATH)\n",
        "\n",
        "print('Finished Training')\n",
        "with open('/content/drive/My Drive/IWAE_VAE/outfile_stage1_mod'+stage1_mod+'stage2_mod'+stage2_mod+'_layer'+str(layer)+'_k'+str(k)+'_'+'.txt', 'a') as outfile:\n",
        "    outfile.write('Finished Training'+'\\n'+'time cost:'+str(time.time()-start)+'\\n')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}